
// This is an autogenerated file from Firebase Studio.
'use server';

/**
 * @fileOverview A product recommendation AI agent that calls an external LLM orchestration service.
 *
 * - getProductRecommendations - A function that handles the product recommendation process.
 * - GetProductRecommendationsInput - The input type for the getProductRecommendations function.
 * - GetProductRecommendationsOutput - The return type for the getProductRecommendations function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';

// Schema for the input to the product recommendations flow
const GetProductRecommendationsInputSchema = z.object({
  productId: z.string().describe('The ID of the product for which to get recommendations.'),
  productDescription: z.string().describe('The description of the product.'),
  userPreferences: z.string().optional().describe('The preferences of the user (e.g., "interested in marketing tools").'),
  numRecommendations: z.number().optional().default(5).describe('Number of recommendations to fetch.'),
});
export type GetProductRecommendationsInput = z.infer<typeof GetProductRecommendationsInputSchema>;

// Schema for a single recommended product, as returned by your LLM Orchestration service
const RecommendedProductSchema = z.object({
  productId: z.string().describe('The ID of the recommended product.'),
  reason: z.string().optional().describe('The reason for the recommendation (e.g., "Similar features", "Often bought together").'),
});

// Schema for the output of the product recommendations flow
const GetProductRecommendationsOutputSchema = z.object({
  recommendations: z.array(RecommendedProductSchema).describe('A list of recommended products with IDs and optional reasons.'),
});
export type GetProductRecommendationsOutput = z.infer<typeof GetProductRecommendationsOutputSchema>;


// Placeholder URL for your LLM Orchestration service (replace with actual URL)
const GET_RECOMMENDATIONS_URL = '/api/mock/llm/get-recommendations'; // Mocked endpoint


export async function getProductRecommendations(input: GetProductRecommendationsInput): Promise<GetProductRecommendationsOutput> {
  return productRecommendationsFlow(input);
}

const productRecommendationsFlow = ai.defineFlow(
  {
    name: 'productRecommendationsFlow',
    inputSchema: GetProductRecommendationsInputSchema,
    outputSchema: GetProductRecommendationsOutputSchema,
  },
  async (input) => {
    // Prepare the request body for your LLM Orchestration service
    const contextDescription = `${input.productDescription}${input.userPreferences ? ` User preferences: ${input.userPreferences}` : ''}`;
    
    const requestBody = {
      productId: input.productId,
      context_description: contextDescription,
      num_recommendations: input.numRecommendations,
    };

    try {
      const response = await fetch(GET_RECOMMENDATIONS_URL, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(requestBody),
      });

      if (!response.ok) {
        const errorBody = await response.text();
        console.error(`Error fetching recommendations: ${response.status} ${errorBody}`);
        throw new Error(`Failed to fetch recommendations: ${response.statusText}`);
      }
      
      // Assuming your API returns data directly matching GetProductRecommendationsOutputSchema
      const recommendationsData = await response.json();
      return GetProductRecommendationsOutputSchema.parse(recommendationsData);

    } catch (error) {
      console.error('Error in product recommendations flow:', error);
      // Return empty recommendations or throw, depending on desired error handling
      return { recommendations: [] };
    }
  }
);
